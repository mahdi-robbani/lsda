{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"LSDA2020_DL_MNIST_with_different_Keras_APIs.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8sGBljtW43eX","colab_type":"text"},"source":["# MNIST with different APIs\n","### Christian Igel, 2020\n","\n","We use TensorFlow 2.x:"]},{"cell_type":"code","metadata":{"id":"XgGovxIY43eY","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","print(\"TensorFlow version:\", tf.__version__)\n","%load_ext tensorboard\n","\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Hlndp0O43eb","colab_type":"text"},"source":["Load, visualize and prepare the MNIST handwritten digit data set:"]},{"cell_type":"code","metadata":{"id":"Y4Qn3TVH43ec","colab_type":"code","colab":{}},"source":["# Load\n","(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","\n","# Helper function for inspecting images\n","def visim(images, rows = 3, cols = 5, scale = 2):\n","    fig = plt.figure(figsize=(cols * scale, rows * scale))\n","    for img_index in range(0, rows*cols):\n","        fig.add_subplot(rows,  cols, img_index+1)\n","        plt.imshow(images[img_index])\n","visim(train_images, 2, 10)\n","\n","# Reshape\n","train_images = train_images[..., tf.newaxis]\n","test_images = test_images[..., tf.newaxis]\n","\n","# Normalize pixel values to be between 0 and 1\n","train_images, test_images = train_images / 255.0, test_images / 255.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0us8dUOc43ee","colab_type":"text"},"source":["First way to define a model:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"J4QW_O9h43ef","colab_type":"code","colab":{}},"source":["# For ReLUs we want ampositive activation in the begining\n","mean_init = 0.05  # Mean of random bias activation\n","sd_init   = 0.01  # Standard deviaion of random bias activation\n","\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Conv2D(32, # Number of output feature maps\n","                                 (3, 3),  # Filter size\n","                                 activation='relu', \n","                                 padding='valid',  # No padding\n","                                 bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init),\n","                                 input_shape=(28, 28, 1)))\n","model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n","model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init)))\n","model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n","model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init)))\n","model.add(tf.keras.layers.Flatten())  # Reshape feature maps into one long vector\n","model.add(tf.keras.layers.Dense(64, activation='relu', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init)))\n","model.add(tf.keras.layers.Dense(10, activation='softmax'))  # Probability distribution over 10 classes\n","\n","print(model.summary())\n","tf.keras.backend.clear_session()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4g8vOkU43eh","colab_type":"text"},"source":["Second way to define a model:"]},{"cell_type":"code","metadata":{"id":"vdwpPTTZ43eh","colab_type":"code","colab":{}},"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(64, activation='relu', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init)),\n","    tf.keras.layers.Dense(10, activation='softmax')])\n","\n","print(model.summary())\n","tf.keras.backend.clear_session()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TWPPUaiP43ek","colab_type":"text"},"source":["Third way, the *functional interface*:"]},{"cell_type":"code","metadata":{"id":"ZIntO6nv43el","colab_type":"code","colab":{}},"source":["# For ReLUs we want ampositive activation in the begining\n","mean_init = 0.05  # Mean of random bias activation\n","sd_init   = 0.01  # Standard deviaion of random bias activation\n","\n","inputs = tf.keras.Input(shape=(28, 28, 1))\n","l = tf.keras.layers.Conv2D(32, (3, 3), \n","                           activation='relu', \n","                           bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init))(inputs)\n","l = tf.keras.layers.MaxPooling2D((2, 2))(l)\n","l = tf.keras.layers.Conv2D(64, (3, 3), bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init), activation='relu')(l)\n","l = tf.keras.layers.MaxPooling2D((2, 2))(l)\n","l = tf.keras.layers.Conv2D(64, (3, 3), bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init), activation='relu')(l)\n","l = tf.keras.layers.Flatten()(l)\n","l = tf.keras.layers.Dense(64, activation='relu', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init))(l)\n","predictions = tf.keras.layers.Dense(10, activation='softmax')(l)\n","\n","# Instantiate model\n","model = tf.keras.Model(inputs=inputs, outputs=predictions)\n","\n","print(model.summary())\n","tf.keras.backend.clear_session()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bZ3KITWC43eo","colab_type":"text"},"source":["Fourth way, *model subclassing API*:"]},{"cell_type":"code","metadata":{"id":"7F7BooC743eo","colab_type":"code","colab":{}},"source":["class MyModel(tf.keras.Model):\n"," def __init__(self, name='Simple_MNIST_Model', **kwargs):\n","   super(MyModel, self).__init__(name=name, **kwargs)\n","   # Define your layers here.\n","   self.conv_1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), use_bias='True', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init))\n","   self.pool_1 = tf.keras.layers.MaxPooling2D((2, 2))\n","   self.conv_2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init))\n","   self.pool_2 = tf.keras.layers.MaxPooling2D((2, 2))\n","   self.conv_3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init))\n","   self.flat = tf.keras.layers.Flatten()\n","   self.dense = tf.keras.layers.Dense(64, activation='relu', bias_initializer=tf.initializers.TruncatedNormal(mean=mean_init, stddev=sd_init))\n","   self.predictions = tf.keras.layers.Dense(10, activation='softmax')\n"," def call(self, inputs, training=None):\n","   # Define your forward pass here,\n","   # using layers you previously defined in `__init__`\n","   # With the Boolean training flag, you can have different bahavior in training and testing \n","   # (e.g., needed for dropout, batch normalization, ...)\n","   return self.predictions(self.dense(self.flat(self.conv_3(self.pool_2(self.conv_2(self.pool_1(self.conv_1(inputs))))))))\n","\n","model = MyModel()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_0qwt7c743eq","colab_type":"text"},"source":["We look inspect the training using TensorBoard:"]},{"cell_type":"markdown","metadata":{"id":"b96MX9hW9kBy","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"3z897fGM43er","colab_type":"code","colab":{}},"source":["# Clean the logs first \n","!mkdir -p /tmp/logs\n","!rm -rf /tmp/logs/MNIST_simple"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n_VbreLy43et","colab_type":"code","colab":{}},"source":["%tensorboard --logdir /tmp/logs/ --host localhost"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G8M2GRT743ev","colab_type":"text"},"source":["Train the model:"]},{"cell_type":"code","metadata":{"id":"JHsdm6Rz43ev","colab_type":"code","colab":{}},"source":["callbacks = [\n","  tf.keras.callbacks.TensorBoard(log_dir='/tmp/logs/MNIST_simple', profile_batch=0)\n","]\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(train_images, train_labels, batch_size=32, epochs=20, callbacks=callbacks)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4hs-wQs43ey","colab_type":"code","colab":{}},"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(\"Test accuracy:\", test_acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5YkKT3o43e0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}