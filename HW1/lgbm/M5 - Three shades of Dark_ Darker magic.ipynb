{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"M5 - Three shades of Dark_ Darker magic.ipynb","provenance":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"1zt7IAVQ6eG3","colab_type":"code","colab":{}},"source":["# General imports\n","import numpy as np\n","import pandas as pd\n","import os, sys, gc, time, warnings, pickle, psutil, random\n","\n","# custom imports\n","from multiprocessing import Pool        # Multiprocess Runs\n","\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"uqomBcGV6eG6","colab_type":"code","colab":{}},"source":["########################### Helpers\n","#################################################################################\n","## Seeder\n","# :seed to make all processes deterministic     # type: int\n","def seed_everything(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","\n","    \n","## Multiprocess Runs\n","def df_parallelize_run(func, t_split):\n","    num_cores = np.min([N_CORES,len(t_split)])\n","    pool = Pool(num_cores)\n","    df = pd.concat(pool.map(func, t_split), axis=1)\n","    pool.close()\n","    pool.join()\n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"0W-MkwJb6eG9","colab_type":"code","colab":{}},"source":["########################### Helper to load data by store ID\n","#################################################################################\n","# Read data\n","def get_data_by_store(store):\n","    \n","    # Read and contact basic feature\n","    df = pd.concat([pd.read_pickle(BASE),\n","                    pd.read_pickle(PRICE).iloc[:,2:],\n","                    pd.read_pickle(CALENDAR).iloc[:,2:]],\n","                    axis=1)\n","    \n","    # Leave only relevant store\n","    df = df[df['store_id']==store]\n","\n","    # With memory limits we have to read \n","    # lags and mean encoding features\n","    # separately and drop items that we don't need.\n","    # As our Features Grids are aligned \n","    # we can use index to keep only necessary rows\n","    # Alignment is good for us as concat uses less memory than merge.\n","    df2 = pd.read_pickle(MEAN_ENC)[mean_features]\n","    df2 = df2[df2.index.isin(df.index)]\n","    \n","    df3 = pd.read_pickle(LAGS).iloc[:,3:]\n","    df3 = df3[df3.index.isin(df.index)]\n","    \n","    df = pd.concat([df, df2], axis=1)\n","    del df2 # to not reach memory limit \n","    \n","    df = pd.concat([df, df3], axis=1)\n","    del df3 # to not reach memory limit \n","    \n","    # Create features list\n","    features = [col for col in list(df) if col not in remove_features]\n","    df = df[['id','d',TARGET]+features]\n","    \n","    # Skipping first n rows\n","    df = df[df['d']>=START_TRAIN].reset_index(drop=True)\n","    \n","    return df, features\n","\n","# Recombine Test set after training\n","def get_base_test():\n","    base_test = pd.DataFrame()\n","\n","    for store_id in STORES_IDS:\n","        temp_df = pd.read_pickle('test_'+store_id+'.pkl')\n","        temp_df['store_id'] = store_id\n","        base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n","    \n","    return base_test\n","\n","\n","########################### Helper to make dynamic rolling lags\n","#################################################################################\n","def make_lag(LAG_DAY):\n","    lag_df = base_test[['id','d',TARGET]]\n","    col_name = 'sales_lag_'+str(LAG_DAY)\n","    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n","    return lag_df[[col_name]]\n","\n","\n","def make_lag_roll(LAG_DAY):\n","    shift_day = LAG_DAY[0]\n","    roll_wind = LAG_DAY[1]\n","    lag_df = base_test[['id','d',TARGET]]\n","    col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n","    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n","    return lag_df[[col_name]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"ZvjjFs8Y6eG_","colab_type":"code","colab":{}},"source":["########################### Model params\n","#################################################################################\n","import lightgbm as lgb\n","lgb_params = {\n","                    'boosting_type': 'gbdt',\n","                    'objective': 'tweedie',\n","                    'tweedie_variance_power': 1.1,\n","                    'metric': 'rmse',\n","                    'subsample': 0.5,\n","                    'subsample_freq': 1,\n","                    'learning_rate': 0.03,\n","                    'num_leaves': 2**11-1,\n","                    'min_data_in_leaf': 2**12-1,\n","                    'feature_fraction': 0.5,\n","                    'max_bin': 100,\n","                    'n_estimators': 10,\n","                    'boost_from_average': False,\n","                    'verbose': -1,\n","                } \n","\n","# Let's look closer on params\n","\n","## 'boosting_type': 'gbdt'\n","# we have 'goss' option for faster training\n","# but it normally leads to underfit.\n","# Also there is good 'dart' mode\n","# but it takes forever to train\n","# and model performance depends \n","# a lot on random factor \n","# https://www.kaggle.com/c/home-credit-default-risk/discussion/60921\n","\n","## 'objective': 'tweedie'\n","# Tweedie Gradient Boosting for Extremely\n","# Unbalanced Zero-inflated Data\n","# https://arxiv.org/pdf/1811.10192.pdf\n","# and many more articles about tweediie\n","#\n","# Strange (for me) but Tweedie is close in results\n","# to my own ugly loss.\n","# My advice here - make OWN LOSS function\n","# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/140564\n","# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/143070\n","# I think many of you already using it (after poisson kernel appeared) \n","# (kagglers are very good with \"params\" testing and tuning).\n","# Try to figure out why Tweedie works.\n","# probably it will show you new features options\n","# or data transformation (Target transformation?).\n","\n","## 'tweedie_variance_power': 1.1\n","# default = 1.5\n","# set this closer to 2 to shift towards a Gamma distribution\n","# set this closer to 1 to shift towards a Poisson distribution\n","# my CV shows 1.1 is optimal \n","# but you can make your own choice\n","\n","## 'metric': 'rmse'\n","# Doesn't mean anything to us\n","# as competition metric is different\n","# and we don't use early stoppings here.\n","# So rmse serves just for general \n","# model performance overview.\n","# Also we use \"fake\" validation set\n","# (as it makes part of the training set)\n","# so even general rmse score doesn't mean anything))\n","# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834\n","\n","## 'subsample': 0.5\n","# Serves to fight with overfit\n","# this will randomly select part of data without resampling\n","# Chosen by CV (my CV can be wrong!)\n","# Next kernel will be about CV\n","\n","##'subsample_freq': 1\n","# frequency for bagging\n","# default value - seems ok\n","\n","## 'learning_rate': 0.03\n","# Chosen by CV\n","# Smaller - longer training\n","# but there is an option to stop \n","# in \"local minimum\"\n","# Bigger - faster training\n","# but there is a chance to\n","# not find \"global minimum\" minimum\n","\n","## 'num_leaves': 2**11-1\n","## 'min_data_in_leaf': 2**12-1\n","# Force model to use more features\n","# We need it to reduce \"recursive\"\n","# error impact.\n","# Also it leads to overfit\n","# that's why we use small \n","# 'max_bin': 100\n","\n","## l1, l2 regularizations\n","# https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c\n","# Good tiny explanation\n","# l2 can work with bigger num_leaves\n","# but my CV doesn't show boost\n","                    \n","## 'n_estimators': 1400\n","# CV shows that there should be\n","# different values for each state/store.\n","# Current value was chosen \n","# for general purpose.\n","# As we don't use any early stopings\n","# careful to not overfit Public LB.\n","\n","##'feature_fraction': 0.5\n","# LightGBM will randomly select \n","# part of features on each iteration (tree).\n","# We have maaaany features\n","# and many of them are \"duplicates\"\n","# and many just \"noise\"\n","# good values here - 0.5-0.7 (by CV)\n","\n","## 'boost_from_average': False\n","# There is some \"problem\"\n","# to code boost_from_average for \n","# custom loss\n","# 'True' makes training faster\n","# BUT carefull use it\n","# https://github.com/microsoft/LightGBM/issues/1514\n","# not our case but good to know cons"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"kHgpRfC16eHB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"w5URJkL06eHE","colab_type":"code","colab":{}},"source":["########################### Vars\n","#################################################################################\n","VER = 2                          # Our model version\n","SEED = 42                        # We want all things\n","seed_everything(SEED)            # to be as deterministic \n","lgb_params['seed'] = SEED        # as possible\n","N_CORES = psutil.cpu_count()     # Available CPU cores\n","\n","\n","#LIMITS and const\n","TARGET      = 'sales'            # Our target\n","START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n","END_TRAIN   = 1913               # End day of our train set\n","P_HORIZON   = 28                 # Prediction horizon\n","USE_AUX     = False               # Use or not pretrained models\n","\n","#FEATURES to remove\n","## These features lead to overfit\n","## or values not present in test set\n","remove_features = ['id','state_id','store_id',\n","                   'date','wm_yr_wk','d',TARGET]\n","mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n","                   'enc_dept_id_mean','enc_dept_id_std',\n","                   'enc_item_id_mean','enc_item_id_std'] \n","\n","#PATHS for Features\n","ORIGINAL = '../input/m5-forecasting-accuracy/'\n","BASE     = '../input/m5-simple-fe/grid_part_1.pkl'\n","PRICE    = '../input/m5-simple-fe/grid_part_2.pkl'\n","CALENDAR = '../input/m5-simple-fe/grid_part_3.pkl'\n","LAGS     = '../input/m5-lags-features/lags_df_28.pkl'\n","MEAN_ENC = '../input/m5-custom-features/mean_encoding_df.pkl'\n","\n","\n","# AUX(pretrained) Models paths\n","AUX_MODELS = '../input/m5-aux-models/'\n","\n","\n","#STORES ids\n","STORES_IDS = pd.read_csv(ORIGINAL+'sales_train_validation.csv')['store_id']\n","STORES_IDS = list(STORES_IDS.unique())\n","\n","\n","#SPLITS for lags creation\n","SHIFT_DAY  = 28\n","N_LAGS     = 15\n","LAGS_SPLIT = [col for col in range(SHIFT_DAY,SHIFT_DAY+N_LAGS)]\n","ROLS_SPLIT = []\n","for i in [1,7,14]:\n","    for j in [7,14,30,60]:\n","        ROLS_SPLIT.append([i,j])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"w2SQMEhU6eHG","colab_type":"code","colab":{}},"source":["########################### Aux Models\n","# If you don't want to wait hours and hours\n","# to have result you can train each store \n","# in separate kernel and then just join result.\n","\n","# If we want to use pretrained models we can \n","## skip training \n","## (in our case do dummy training\n","##  to show that we are good with memory\n","##  and you can safely use this (all kernel) code)\n","if USE_AUX:\n","    lgb_params['n_estimators'] = 2\n","    \n","# Here is some 'logs' that can compare\n","#Train CA_1\n","#[100]\tvalid_0's rmse: 2.02289\n","#[200]\tvalid_0's rmse: 2.0017\n","#[300]\tvalid_0's rmse: 1.99239\n","#[400]\tvalid_0's rmse: 1.98471\n","#[500]\tvalid_0's rmse: 1.97923\n","#[600]\tvalid_0's rmse: 1.97284\n","#[700]\tvalid_0's rmse: 1.96763\n","#[800]\tvalid_0's rmse: 1.9624\n","#[900]\tvalid_0's rmse: 1.95673\n","#[1000]\tvalid_0's rmse: 1.95201\n","#[1100]\tvalid_0's rmse: 1.9476\n","#[1200]\tvalid_0's rmse: 1.9434\n","#[1300]\tvalid_0's rmse: 1.9392\n","#[1400]\tvalid_0's rmse: 1.93446\n","\n","#Train CA_2\n","#[100]\tvalid_0's rmse: 1.88949\n","#[200]\tvalid_0's rmse: 1.84767\n","#[300]\tvalid_0's rmse: 1.83653\n","#[400]\tvalid_0's rmse: 1.82909\n","#[500]\tvalid_0's rmse: 1.82265\n","#[600]\tvalid_0's rmse: 1.81725\n","#[700]\tvalid_0's rmse: 1.81252\n","#[800]\tvalid_0's rmse: 1.80736\n","#[900]\tvalid_0's rmse: 1.80242\n","#[1000]\tvalid_0's rmse: 1.79821\n","#[1100]\tvalid_0's rmse: 1.794\n","#[1200]\tvalid_0's rmse: 1.78973\n","#[1300]\tvalid_0's rmse: 1.78552\n","#[1400]\tvalid_0's rmse: 1.78158"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"UCeG80Wr6eHI","colab_type":"code","colab":{}},"source":["#training loop explanationa \n","STORES_IDS # CA_1, CA_2.. WI_3\n","#grid_df is a df with all items of a store, also has sell price, max price, min price and various rolling means\n","#I guess it loads rolling means from the mean encoding pickle file\n","grid_df, feature_cols = get_data_by_store('CA_1') #feature cols is just cols of the df\n","train_mask = grid_df['d']<=END_TRAIN #index of rows for d 0 to 1900\n","#the data frame basically is organized like:\n","#item1 day1 features\n","#...\n","#item1 day 1900 features\n","#item2 day 1 features\n","#...\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"NXqbAFX26eHK","colab_type":"code","colab":{}},"source":["# grid_df\n","# train_mask = grid_df['d']<=END_TRAIN\n","# train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"jN4EqthM6eHN","colab_type":"code","colab":{}},"source":["########################### Train Models\n","#################################################################################\n","for store_id in STORES_IDS:\n","    print('Train', store_id)\n","    \n","    # Get grid for current store\n","    grid_df, features_columns = get_data_by_store(store_id)\n","    \n","    # Masks for \n","    # Train (All data less than 1913)\n","    # \"Validation\" (Last 28 days - not real validatio set)\n","    # Test (All data greater than 1913 day, \n","    #       with some gap for recursive features)\n","    train_mask = grid_df['d']<=END_TRAIN\n","    valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n","    preds_mask = grid_df['d']>(END_TRAIN-100)\n","    \n","    # Apply masks and save lgb dataset as bin\n","    # to reduce memory spikes during dtype convertations\n","    # https://github.com/Microsoft/LightGBM/issues/1032\n","    # \"To avoid any conversions, you should always use np.float32\"\n","    # or save to bin before start training\n","    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n","    train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n","                       label=grid_df[train_mask][TARGET])\n","    train_data.save_binary('train_data.bin')\n","    train_data = lgb.Dataset('train_data.bin')\n","    \n","    valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n","                       label=grid_df[valid_mask][TARGET])\n","    \n","    # Saving part of the dataset for later predictions\n","    # Removing features that we need to calculate recursively \n","    grid_df = grid_df[preds_mask].reset_index(drop=True)\n","    keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n","    grid_df = grid_df[keep_cols]\n","    grid_df.to_pickle('test_'+store_id+'.pkl')\n","    del grid_df\n","    \n","    # Launch seeder again to make lgb training 100% deterministic\n","    # with each \"code line\" np.random \"evolves\" \n","    # so we need (may want) to \"reset\" it\n","    seed_everything(SEED)\n","    estimator = lgb.train(lgb_params,\n","                          train_data,\n","                          valid_sets = [valid_data],\n","                          verbose_eval = 100,\n","                          )\n","    \n","    # Save model - it's not real '.bin' but a pickle file\n","    # estimator = lgb.Booster(model_file='model.txt')\n","    # can only predict with the best iteration (or the saving iteration)\n","    # pickle.dump gives us more flexibility\n","    # like estimator.predict(TEST, num_iteration=100)\n","    # num_iteration - number of iteration want to predict with, \n","    # NULL or <= 0 means use best iteration\n","    model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n","    pickle.dump(estimator, open(model_name, 'wb'))\n","\n","    # Remove temporary files and objects \n","    # to free some hdd space and ram memory\n","    !rm train_data.bin\n","    del train_data, valid_data, estimator\n","    gc.collect()\n","    \n","    # \"Keep\" models features for predictions\n","    MODEL_FEATURES = features_columns"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"qK2f1bBJ6eHP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"4O1w05TL6eHR","colab_type":"code","colab":{}},"source":["########################### Predict\n","#################################################################################\n","\n","# Create Dummy DataFrame to store predictions\n","all_preds = pd.DataFrame()\n","\n","# Join back the Test dataset with \n","# a small part of the training data \n","# to make recursive features\n","base_test = get_base_test()\n","\n","# Timer to measure predictions time \n","main_time = time.time()\n","\n","# Loop over each prediction day\n","# As rolling lags are the most timeconsuming\n","# we will calculate it for whole day\n","for PREDICT_DAY in range(1,29):    \n","    print('Predict | Day:', PREDICT_DAY)\n","    start_time = time.time()\n","\n","    # Make temporary grid to calculate rolling lags\n","    grid_df = base_test.copy()\n","    grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1)\n","        \n","    for store_id in STORES_IDS:\n","        \n","        # Read all our models and make predictions\n","        # for each day/store pairs\n","        model_path = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin' \n","        if USE_AUX:\n","            model_path = AUX_MODELS + model_path\n","        \n","        estimator = pickle.load(open(model_path, 'rb'))\n","        \n","        day_mask = base_test['d']==(END_TRAIN+PREDICT_DAY)\n","        store_mask = base_test['store_id']==store_id\n","        \n","        mask = (day_mask)&(store_mask)\n","        base_test[TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n","    \n","    # Make good column naming and add \n","    # to all_preds DataFrame\n","    temp_df = base_test[day_mask][['id',TARGET]]\n","    temp_df.columns = ['id','F'+str(PREDICT_DAY)]\n","    if 'id' in list(all_preds):\n","        all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n","    else:\n","        all_preds = temp_df.copy()\n","        \n","    print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n","                  ' %0.2f min total |' % ((time.time() - main_time) / 60),\n","                  ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n","    del temp_df\n","    \n","all_preds = all_preds.reset_index(drop=True)\n","all_preds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"cWWD8mhh6eHU","colab_type":"code","colab":{}},"source":["########################### Export\n","#################################################################################\n","# Reading competition sample submission and\n","# merging our predictions\n","# As we have predictions only for \"_validation\" data\n","# we need to do fillna() for \"_evaluation\" items\n","submission = pd.read_csv(ORIGINAL+'sample_submission.csv')[['id']]\n","submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n","submission.to_csv('submission_v'+str(VER)+'.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"CrAss-7r6eHX","colab_type":"code","colab":{}},"source":["# Summary\n","\n","# Of course here is no magic at all.\n","# No \"Novel\" features and no brilliant ideas.\n","# We just carefully joined all\n","# our previous fe work and created a model.\n","\n","# Also!\n","# In my opinion this strategy is a \"dead end\".\n","# Overfits a lot LB and with 1 final submission \n","# you have no option to risk.\n","\n","\n","# Improvement should come from:\n","# Loss function\n","# Data representation\n","# Stable CV\n","# Good features reduction strategy\n","# Predictions stabilization with NN\n","# Trend prediction\n","# Real zero sales detection/classification\n","\n","\n","# Good kernels references \n","## (the order is random and the list is not complete):\n","# https://www.kaggle.com/ragnar123/simple-lgbm-groupkfold-cv\n","# https://www.kaggle.com/jpmiller/grouping-items-by-stockout-pattern\n","# https://www.kaggle.com/headsortails/back-to-predict-the-future-interactive-m5-eda\n","# https://www.kaggle.com/sibmike/m5-out-of-stock-feature\n","# https://www.kaggle.com/mayer79/m5-forecast-attack-of-the-data-table\n","# https://www.kaggle.com/yassinealouini/seq2seq\n","# https://www.kaggle.com/kailex/m5-forecaster-v2\n","# https://www.kaggle.com/aerdem4/m5-lofo-importance-on-gpu-via-rapids-xgboost\n","\n","\n","# Features were created in these kernels:\n","## \n","# Mean encodings and PCA options\n","# https://www.kaggle.com/kyakovlev/m5-custom-features\n","##\n","# Lags and rolling lags\n","# https://www.kaggle.com/kyakovlev/m5-lags-features\n","##\n","# Base Grid and base features (calendar/price/etc)\n","# https://www.kaggle.com/kyakovlev/m5-simple-fe\n","\n","\n","# Personal request\n","# Please don't upvote any ensemble and copypaste kernels\n","## The worst case is ensemble without any analyse.\n","## The best choice - just ignore it.\n","## I would like to see more kernels with interesting and original approaches.\n","## Don't feed copypasters with upvotes.\n","\n","## It doesn't mean that you should not fork and improve others kernels\n","## but I would like to see params and code tuning based on some CV and analyse\n","## and not only on LB probing.\n","## Small changes could be shared in comments and authors can improve their kernel.\n","\n","## Feel free to criticize this kernel as my knowlege is very limited\n","## and I can be wrong in code and descriptions. \n","## Thank you."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hkvHwgOPr_U","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":109},"outputId":"b0a597a4-856e-4c78-8348-b7e00db85867"},"source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-8fe55b0b-f39a-4ab1-9f74-f24509702f8a\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-8fe55b0b-f39a-4ab1-9f74-f24509702f8a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving m5-custom-features.zip to m5-custom-features.zip\n","Saving m5-lags-features.zip to m5-lags-features.zip\n"],"name":"stdout"}]}]}